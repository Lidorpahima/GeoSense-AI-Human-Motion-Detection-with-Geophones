<!-- Paste this into your GitHub README.md as an HTML block -->
<h1>Background Noise Classification, Human &amp; Vehicle Detection in Noisy Environments</h1>

<p>
  <a href="https://www.python.org/downloads/release/python-390/">
    <img src="https://img.shields.io/badge/python-3.9-blue.svg" alt="Python 3.9" />
  </a>
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&amp;logo=PyTorch&amp;logoColor=white" alt="PyTorch" />
  </a>
  <a href="https://opensource.org/licenses/MIT">
    <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" />
  </a>
</p>



<hr />

<h2>üìñ Project Overview</h2>
<p>
  This project explores an alternative dimension for surveillance and activity monitoring: the subtle vibrations of the ground itself. Traditional surveillance technologies often fail when faced with real-world challenges like obstructed lines of sight, adverse weather, or the need for covert operation.
</p>
<p>
  This research demonstrates a robust deep-learning pipeline that uses <strong>geophone</strong> sensors to "listen" to ground vibrations and classify them into three distinct categories:
</p>
<ol>
  <li><strong>Quiet</strong>: Baseline noise with no significant event.</li>
  <li><strong>Vehicle</strong>: Vibrations caused by vehicular movement.</li>
  <li><strong>Human</strong>: Vibrations generated by human footsteps or activity.</li>
</ol>
<p>
  By leveraging a <strong>Dilated Convolutional Autoencoder (DCAE)</strong> for unsupervised feature learning, followed by a fine-tuned classifier, our model achieves high accuracy and reliability, proving the feasibility of seismic sensing as a primary or complementary method for covert, weather-independent detection.
</p>

<h2>‚ú® Key Features</h2>
<ul>
  <li><strong>End-to-End Pipeline</strong>: From raw geophone signals to final classification.</li>
  <li><strong>Unsupervised Pre-training</strong>: Learns robust signal features from unlabeled data using a Dilated Convolutional Autoencoder (DCAE).</li>
  <li><strong>Supervised Fine-Tuning</strong>: The pre-trained encoder is fine-tuned for the specific classification task.</li>
  <li><strong>Advanced Data Augmentation</strong>: Noise addition, time shifting, amplitude scaling.</li>
  <li><strong>High Performance</strong>: Final test accuracy of <strong>94.95%</strong>.</li>
</ul>

<h2>üõ†Ô∏è The Method: A Multi-Stage Pipeline</h2>
<ol>
  <li>
    <strong>Data Collection &amp; Preprocessing</strong><br>
    Raw geophone signals (1 kHz sampling) ‚Üí 0.5 s overlapping segments ‚Üí normalization.
  </li>
  <li>
    <strong>Unsupervised Representation Learning (DCAE)</strong><br>
    Train Dilated Convolutional Autoencoder to reconstruct inputs, forcing the encoder to learn compact latent features.
  </li>
  <li>
    <strong>Supervised Classifier Training</strong><br>
    Attach a new classifier head to the pre-trained encoder and fine-tune on labeled data with augmentation.
  </li>
  <li>
    <strong>Rigorous Evaluation</strong><br>
    Assess on held-out test set for unbiased performance metrics.
  </li>
</ol>

<h2>üß† Model Architecture</h2>
<h3>1. Dilated Convolutional Autoencoder (DCAE)</h3>
<ul>
  <li><strong>Encoder</strong>: Four blocks of 1D dilated convolutions ‚Üí 64-dim latent space.</li>
  <li><strong>Decoder</strong>: Reconstructs signal from latent code.</li>
  <li><strong>Skip Connections</strong>: Preserve fine details (U-Net style).</li>
</ul>

<h3>2. Classifier with Fine-Tuned Encoder</h3>
<ul>
  <li><strong>Pre-trained Encoder</strong>: Weights unfrozen and fine-tuned.</li>
  <li><strong>Classifier Head</strong>: MLP (Linear ‚Üí BatchNorm ‚Üí GELU ‚Üí Dropout) ‚Üí 3-class logits.</li>
</ul>

<h2>üìä Results and Discussion</h2>
<p>The combination of fine-tuning and augmentation yields the best performance:</p>
<table>
  <thead>
    <tr>
      <th>#</th>
      <th>Configuration</th>
      <th>Test Accuracy</th>
      <th>Key Observation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Baseline (No Augmentation, No Fine-tuning)</td>
      <td>50.32%</td>
      <td>Unstable, poor generalization.</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Augmentation Only</td>
      <td>77.08%</td>
      <td>Better generalization, fixed features.</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Fine-Tuned Encoder Only</td>
      <td>92.38%</td>
      <td>High precision, stable learning.</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Final Model (Fine-Tuned + Augmentation)</td>
      <td><strong>94.95%</strong></td>
      <td>Best overall, minimal false alarms.</td>
    </tr>
  </tbody>
</table>

<h2>üöÄ How to Run</h2>
<ol>
  <li>
    <strong>Clone the repo:</strong><br>
    <code>git clone https://github.com/your-username/your-repo-name.git</code>
  </li>
  <li>
    <strong>Install deps:</strong><br>
    <code>python -m venv venv<br>
    source venv/bin/activate  # Windows: venv\Scripts\activate<br>
    pip install -r requirements.txt</code>
  </li>
  <li>
    <strong>Prepare data:</strong><br>
    Place raw <code>.csv</code> files in <code>data/</code>.
  </li>
  <li>
    <strong>Run training &amp; evaluation:</strong><br>
    <code>python main.py</code>
  </li>
</ol>

<h2>üíª Technologies Used</h2>
<p>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40" />
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pytorch/pytorch-original.svg" alt="pytorch" width="40" height="40" />
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/numpy/numpy-original.svg" alt="numpy" width="40" height="40" />
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40" />
  <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="scikit-learn" width="40" height="40" />
</p>

<h2>üèÅ Conclusion</h2>
<p>
  A hybrid Dilated Convolutional Autoencoder + fine-tuning approach achieves 94.95% accuracy on seismic geophone signal classification, demonstrating the promise of seismic sensing for security, infrastructure monitoring, and environmental applications. Future extensions may include more classes, edge-device deployment, and transformer-based enhancements.
</p>
