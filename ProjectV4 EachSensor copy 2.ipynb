{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# --- 专转 转 (砖 转 转 爪专) ---\n",
    "DATA_PATH = \"your_data_folder_path\"  # <--- 砖 转 转 砖!\n",
    "SEQUENCE_LENGTH = 512\n",
    "HOP_SIZE = 256\n",
    "SEED = 42\n",
    "N_SPLITS = 5  # 住驻专 -Folds -Cross-Validation 砖 -Classifier\n",
    "\n",
    "# 驻专专 砖 Autoencoder ( )\n",
    "AE_BATCH_SIZE = 64\n",
    "ENCODING_DIM_AE = 64\n",
    "AE_DROPOUT_RATE = 0.1\n",
    "AE_LEARNING_RATE = 1e-3\n",
    "AE_WEIGHT_DECAY = 1e-4\n",
    "AE_TRAIN_EPOCHS_SINGLE = 75 # 住驻专 epochs  -AE , 驻砖专 转\n",
    "AE_PATIENCE_SINGLE = 15     # 住转 -early stopping 砖 -AE \n",
    "AE_INPUT_NOISE_STD = 0.05\n",
    "AE_PLOT_RECONSTRUCTION_SINGLE = True # 爪 专祝 砖专 砖 -AE \n",
    "\n",
    "# 驻专专 砖 Classifier (注专 K-Fold)\n",
    "CLASSIFIER_BATCH_SIZE = 64\n",
    "CLASSIFIER_EPOCHS = 100 # 驻砖专 转, 转  专 转住\n",
    "CLASSIFIER_PATIENCE = 25\n",
    "CLASSIFIER_LR = 1e-3\n",
    "CLASSIFIER_WEIGHT_DECAY = 1e-3\n",
    "CLASSIFIER_NUM_AUG_PER_SAMPLE = 2\n",
    "\n",
    "# 专转 转拽 (GPU  )\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"CUDA Seed Set. Deterministic: {torch.backends.cudnn.deterministic}, Benchmark: {torch.backends.cudnn.benchmark}\")\n",
    "\n",
    "\n",
    "# --- 拽 1: 注转 转 转 ---\n",
    "def load_and_prepare_data(data_path_folder):\n",
    "    file_mapping = {\n",
    "        'car_nothing(AVI).csv': 'quiet',\n",
    "        'carnew(AVI).csv': 'vehicle',\n",
    "        'human_nothing(AVI).csv': 'quiet',\n",
    "        'human(AVI).csv': 'human'\n",
    "    }\n",
    "    label_encoding = {'quiet': 0, 'vehicle': 1, 'human': 2}\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    if not os.path.exists(data_path_folder):\n",
    "        print(f\"Data folder {data_path_folder} not found. Please ensure the path is correct.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    print(f\"Loading data from: {data_path_folder}\")\n",
    "    for filename, activity_type in file_mapping.items():\n",
    "        filepath = os.path.join(data_path_folder, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Warning: File not found at {filepath}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, header=None)\n",
    "            if not df.empty and df.shape[1] > 0:\n",
    "                data_values = df.iloc[:, 0].values.astype(np.float32) # Ensure float32 for PyTorch\n",
    "                all_data.extend(data_values)\n",
    "                all_labels.extend([label_encoding[activity_type]] * len(data_values))\n",
    "                print(f\"  Successfully loaded {len(data_values)} points from {filename} as '{activity_type}'\")\n",
    "            else:\n",
    "                print(f\"  Warning: File {filename} is empty or has no data columns. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading {filename}: {e}\")\n",
    "\n",
    "    all_data_np = np.array(all_data)\n",
    "    all_labels_np = np.array(all_labels)\n",
    "\n",
    "    if len(all_data_np) == 0:\n",
    "        print(\"No data was loaded. Check DATA_PATH and file contents.\")\n",
    "    else:\n",
    "        print(f\"Total raw data points loaded: {len(all_data_np)}\")\n",
    "    return all_data_np, all_labels_np\n",
    "\n",
    "def create_sequences_with_overlap(data, labels, sequence_length, hop_size):\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    unique_labels_vals = np.unique(labels)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(\"Cannot create sequences from empty raw data.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    print(f\"Creating sequences with length {sequence_length} and hop {hop_size}...\")\n",
    "    for label_val in unique_labels_vals:\n",
    "        label_indices = np.where(labels == label_val)[0]\n",
    "        current_label_data = data[label_indices]\n",
    "\n",
    "        if len(current_label_data) < sequence_length:\n",
    "            print(f\"  Not enough data for label {label_val} to create a sequence of length {sequence_length}. Has {len(current_label_data)} points. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        num_sequences_for_label = 0\n",
    "        if sequence_length == hop_size:\n",
    "             num_sequences_for_label = len(current_label_data) // sequence_length\n",
    "        elif len(current_label_data) >= sequence_length :\n",
    "            num_sequences_for_label = (len(current_label_data) - sequence_length) // hop_size + 1\n",
    "        else: # Should be caught by the check above, but as a safeguard\n",
    "            print(f\"  Unexpectedly few data for label {label_val} after length check. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  For label {label_val}, creating {num_sequences_for_label} sequences.\")\n",
    "        for i in range(num_sequences_for_label):\n",
    "            start_idx = i * hop_size\n",
    "            end_idx = start_idx + sequence_length\n",
    "            sequences.append(current_label_data[start_idx:end_idx])\n",
    "            sequence_labels.append(label_val)\n",
    "\n",
    "    if not sequences:\n",
    "        print(\"No sequences were created. Check data, sequence_length, and hop_size.\")\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    return np.array(sequences, dtype=np.float32), np.array(sequence_labels)\n",
    "\n",
    "# --- 驻拽爪转 注专  ---\n",
    "def get_padding_for_dilation(kernel_size, dilation):\n",
    "    return (kernel_size - 1) * dilation // 2\n",
    "\n",
    "def add_noise_to_batch(batch_x, noise_std, device, is_training):\n",
    "    if noise_std > 0 and is_training:\n",
    "        noise = torch.randn_like(batch_x) * noise_std\n",
    "        return batch_x + noise.to(device)\n",
    "    return batch_x\n",
    "\n",
    "def plot_ae_reconstructions(model, dataloader, device, num_samples=3, epoch_num=None, current_loss=None, sequence_length_param=SEQUENCE_LENGTH, plot_now=True, title_prefix=\"\"):\n",
    "    if not plot_now or num_samples == 0:\n",
    "        return\n",
    "        \n",
    "    model.eval()\n",
    "    samples_done = 0\n",
    "    fig_height = 2.5 * num_samples\n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(12, fig_height), squeeze=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x_val, _ in dataloader:\n",
    "            batch_x_val_original = batch_x_val.clone().to(device)\n",
    "            reconstructed_x_val = model(batch_x_val_original)\n",
    "\n",
    "            for i in range(batch_x_val_original.size(0)):\n",
    "                if samples_done < num_samples:\n",
    "                    original_signal = batch_x_val_original[i].cpu().squeeze().numpy()\n",
    "                    reconstructed_signal = reconstructed_x_val[i].cpu().squeeze().numpy()\n",
    "                    ax = axes[samples_done, 0]\n",
    "                    ax.plot(original_signal, label='Original Signal', color='blue', alpha=0.7)\n",
    "                    ax.plot(reconstructed_signal, label='Reconstructed Signal', color='red', linestyle='--')\n",
    "                    mse_sample = np.mean((original_signal - reconstructed_signal)**2)\n",
    "                    ax.legend()\n",
    "                    ax.set_title(f\"Example {samples_done+1} (Sample MSE: {mse_sample:.4f})\")\n",
    "                    ax.set_xlabel(\"Time Points\")\n",
    "                    ax.set_ylabel(\"Amplitude\")\n",
    "                    ax.grid(True, linestyle=':', alpha=0.7)\n",
    "                    ax.set_xlim(0, sequence_length_param)\n",
    "                    samples_done += 1\n",
    "                else:\n",
    "                    break\n",
    "            if samples_done >= num_samples:\n",
    "                break\n",
    "    \n",
    "    title_parts = [title_prefix, \"Autoencoder Reconstructions\"]\n",
    "    if epoch_num is not None: title_parts.append(f\"Epoch {epoch_num}\")\n",
    "    if current_loss is not None: title_parts.append(f\"Val Loss: {current_loss:.6f}\")\n",
    "        \n",
    "    fig.suptitle(\" - \".join(filter(None, title_parts)), fontsize=16) # filter(None, ...) removes empty strings\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "class DilatedConvEncoderA(nn.Module):\n",
    "    def __init__(self, input_channels=1, encoding_dim=ENCODING_DIM_AE, dropout_rate=AE_DROPOUT_RATE):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, dilation=1, padding=get_padding_for_dilation(5,1))\n",
    "        self.norm1 = nn.GroupNorm(8, 32); self.relu1 = nn.ReLU(); self.drop1 = nn.Dropout(dropout_rate)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, dilation=2, padding=get_padding_for_dilation(5,2))\n",
    "        self.norm2 = nn.GroupNorm(8, 64); self.relu2 = nn.ReLU(); self.drop2 = nn.Dropout(dropout_rate)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, dilation=4, padding=get_padding_for_dilation(5,4))\n",
    "        self.norm3 = nn.GroupNorm(16, 128); self.relu3 = nn.ReLU(); self.drop3 = nn.Dropout(dropout_rate)\n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size=5, dilation=8, padding=get_padding_for_dilation(5,8))\n",
    "        self.norm4 = nn.GroupNorm(16, 256); self.relu4 = nn.ReLU(); self.drop4 = nn.Dropout(dropout_rate)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc_encoded = nn.Linear(256, encoding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1 = self.drop1(self.relu1(self.norm1(self.conv1(x))))\n",
    "        s2 = self.drop2(self.relu2(self.norm2(self.conv2(s1))))\n",
    "        s3 = self.drop3(self.relu3(self.norm3(self.conv3(s2))))\n",
    "        s4 = self.drop4(self.relu4(self.norm4(self.conv4(s3))))\n",
    "        pooled = self.adaptive_pool(s4)\n",
    "        encoded = self.fc_encoded(pooled.squeeze(-1))\n",
    "        return encoded, (s1, s2, s3, s4)\n",
    "\n",
    "class DilatedConvDecoderA(nn.Module):\n",
    "    def __init__(self, output_channels=1, encoding_dim=ENCODING_DIM_AE, dropout_rate=AE_DROPOUT_RATE, sequence_length_param=SEQUENCE_LENGTH):\n",
    "        super().__init__()\n",
    "        self.fc_decoded = nn.Linear(encoding_dim, 256 * 1)\n",
    "        self.upsample_initial = nn.Upsample(size=sequence_length_param, mode='nearest')\n",
    "        self.conv_t4 = nn.ConvTranspose1d(256 + 256, 128, kernel_size=5, dilation=8, padding=get_padding_for_dilation(5,8))\n",
    "        self.norm_t4 = nn.GroupNorm(16, 128); self.relu_t4 = nn.ReLU(); self.drop_t4 = nn.Dropout(dropout_rate)\n",
    "        self.conv_t3 = nn.ConvTranspose1d(128 + 128, 64, kernel_size=5, dilation=4, padding=get_padding_for_dilation(5,4))\n",
    "        self.norm_t3 = nn.GroupNorm(8, 64); self.relu_t3 = nn.ReLU(); self.drop_t3 = nn.Dropout(dropout_rate)\n",
    "        self.conv_t2 = nn.ConvTranspose1d(64 + 64, 32, kernel_size=5, dilation=2, padding=get_padding_for_dilation(5,2))\n",
    "        self.norm_t2 = nn.GroupNorm(8, 32); self.relu_t2 = nn.ReLU(); self.drop_t2 = nn.Dropout(dropout_rate)\n",
    "        self.conv_t1 = nn.ConvTranspose1d(32 + 32, output_channels, kernel_size=5, dilation=1, padding=get_padding_for_dilation(5,1))\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        s1, s2, s3, s4 = skips\n",
    "        x = self.fc_decoded(x); x = x.unsqueeze(-1); x = self.upsample_initial(x)\n",
    "        x = torch.cat([x, s4], dim=1); x = self.drop_t4(self.relu_t4(self.norm_t4(self.conv_t4(x))))\n",
    "        x = torch.cat([x, s3], dim=1); x = self.drop_t3(self.relu_t3(self.norm_t3(self.conv_t3(x))))\n",
    "        x = torch.cat([x, s2], dim=1); x = self.drop_t2(self.relu_t2(self.norm_t2(self.conv_t2(x))))\n",
    "        x = torch.cat([x, s1], dim=1); decoded = self.conv_t1(x)\n",
    "        return decoded\n",
    "\n",
    "class DilatedAutoencoderA(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_channels=1, encoding_dim=ENCODING_DIM_AE, dropout_rate=AE_DROPOUT_RATE, sequence_length_param=SEQUENCE_LENGTH):\n",
    "        super().__init__()\n",
    "        self.encoder = DilatedConvEncoderA(input_channels, encoding_dim, dropout_rate)\n",
    "        self.decoder = DilatedConvDecoderA(output_channels, encoding_dim, dropout_rate, sequence_length_param)\n",
    "    def forward(self, x):\n",
    "        encoded, skips = self.encoder(x)\n",
    "        decoded = self.decoder(encoded, skips)\n",
    "        return decoded\n",
    "\n",
    "def advanced_seismic_augmentation(signal, augment_prob=0.7): # signal is expected to be 1D tensor here\n",
    "    if random.random() > augment_prob: return signal\n",
    "    augmented = signal.clone()\n",
    "    # 1. Gaussian noise\n",
    "    if random.random() < 0.45: augmented += torch.randn_like(signal) * random.uniform(0.01, 0.05)\n",
    "    # 2. Time shifting\n",
    "    if random.random() < 0.25:\n",
    "        max_shift = int(signal.shape[-1] * 0.05)\n",
    "        if max_shift > 0 : # only shift if possible\n",
    "            shift = random.randint(-max_shift, max_shift)\n",
    "            augmented = torch.roll(augmented, shift, dims=-1)\n",
    "    # 3. Amplitude scaling\n",
    "    if random.random() < 0.25: augmented *= random.uniform(0.8, 1.2)\n",
    "    # 4. Time stretching (more careful with dimensions)\n",
    "    if random.random() < 0.2 and signal.shape[-1] > 1 : # Ensure signal is not too short\n",
    "        stretch_factor = random.uniform(0.95, 1.05)\n",
    "        length = signal.shape[-1]; new_length = int(length * stretch_factor)\n",
    "        if new_length < 1: new_length = 1 # ensure new_length is at least 1\n",
    "\n",
    "        # Add batch and channel dim for interpolate, then remove\n",
    "        stretched = F.interpolate(signal.unsqueeze(0).unsqueeze(0), size=new_length, mode='linear', align_corners=False).squeeze(0).squeeze(0)\n",
    "        \n",
    "        if stretched.shape[-1] != length: # Resize back to original length\n",
    "            if stretched.shape[-1] < 1: # if somehow it became empty\n",
    "                 stretched = torch.zeros_like(signal) # fallback or handle error\n",
    "            else:\n",
    "                stretched = F.interpolate(stretched.unsqueeze(0).unsqueeze(0), size=length, mode='linear', align_corners=False).squeeze(0).squeeze(0)\n",
    "        augmented = stretched\n",
    "    return augmented\n",
    "\n",
    "\n",
    "class SingleStrongClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_encoder, encoding_dim=ENCODING_DIM_AE, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.encoder = pretrained_encoder\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True # Fine-tuning 注\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(encoding_dim), nn.Dropout(0.2), nn.Linear(encoding_dim, 512), nn.GELU(),\n",
    "            nn.BatchNorm1d(512), nn.Dropout(0.4), nn.Linear(512, 256), nn.GELU(),\n",
    "            nn.BatchNorm1d(256), nn.Dropout(0.3), nn.Linear(256, 128), nn.GELU(),\n",
    "            nn.BatchNorm1d(128), nn.Dropout(0.2), nn.Linear(128, 64), nn.GELU(),\n",
    "            nn.BatchNorm1d(64), nn.Dropout(0.1), nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        features, _ = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def get_cosine_scheduler(optimizer, num_epochs, warmup_epochs=5):\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs: return epoch / warmup_epochs if warmup_epochs > 0 else 1.0\n",
    "        else:\n",
    "            progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs) if (num_epochs - warmup_epochs) > 0 else 0\n",
    "            return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "def aggregate_curves(curves_list_of_lists):\n",
    "    if not curves_list_of_lists or not any(curves_list_of_lists): return np.array([]), np.array([])\n",
    "    # Filter out empty lists if any from folds that might have stopped very early\n",
    "    valid_curves = [c for c in curves_list_of_lists if c]\n",
    "    if not valid_curves: return np.array([]), np.array([])\n",
    "\n",
    "    max_len = max(len(c) for c in valid_curves)\n",
    "    padded_curves = [np.pad(c, (0, max_len - len(c)), 'edge') for c in valid_curves] # Pad with last value\n",
    "    curves_np = np.array(padded_curves)\n",
    "    mean_curve = np.mean(curves_np, axis=0)\n",
    "    std_curve = np.std(curves_np, axis=0)\n",
    "    return mean_curve, std_curve\n",
    "\n",
    "# --- 注转 转 专砖转 ---\n",
    "print(\"--- Initial Data Loading and Preparation ---\")\n",
    "X_raw, y_raw = load_and_prepare_data(DATA_PATH)\n",
    "if len(X_raw) == 0:\n",
    "    print(\"No raw data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "X_sequences, y_sequences = create_sequences_with_overlap(X_raw, y_raw, SEQUENCE_LENGTH, HOP_SIZE)\n",
    "if len(X_sequences) == 0:\n",
    "    print(\"No sequences were created. Exiting.\")\n",
    "    exit()\n",
    "print(f\"Total sequences created: {len(X_sequences)}\")\n",
    "num_unique_classes = len(np.unique(y_sequences))\n",
    "print(f\"Number of unique classes in sequences: {num_unique_classes}\")\n",
    "\n",
    "\n",
    "# --- 砖 专 K-Fold:  Autoencoder  ---\n",
    "print(\"\\n--- Pre K-Fold: Single Autoencoder Training ---\")\n",
    "# 拽: 80%  住拽住 /爪 砖 -AE, 转 20% 爪 驻转 砖 -AE.\n",
    "# -20% 转专  住拽住 砖砖 -X_test_final 注专 -classifier.\n",
    "X_for_kfold_and_ae_val, X_test_final, y_for_kfold_and_ae_val, y_test_final = train_test_split(\n",
    "    X_sequences, y_sequences, test_size=0.2, random_state=SEED, stratify=y_sequences # 20% 拽爪转  住驻转\n",
    ")\n",
    "# 转 -80% 转专, 拽 75%  -AE -25% 爪 砖 -AE\n",
    "X_train_ae_single, X_val_ae_single, _, _ = train_test_split( # y  专 -AE\n",
    "    X_for_kfold_and_ae_val, y_for_kfold_and_ae_val, # y 专拽 爪专 stratify\n",
    "    test_size=0.25, random_state=SEED, stratify=y_for_kfold_and_ae_val\n",
    ")\n",
    "\n",
    "print(f\"Data for single AE training: {len(X_train_ae_single)} sequences\")\n",
    "print(f\"Data for single AE validation: {len(X_val_ae_single)} sequences\")\n",
    "print(f\"Data for classifier K-Fold (train/val): {len(X_for_kfold_and_ae_val)} sequences\")\n",
    "print(f\"Data for final classifier test set: {len(X_test_final)} sequences\")\n",
    "\n",
    "# 专 注专  -AE \n",
    "scaler_ae_single = StandardScaler()\n",
    "X_train_ae_single_flat = X_train_ae_single.reshape(-1, 1); scaler_ae_single.fit(X_train_ae_single_flat)\n",
    "X_train_ae_single_norm = scaler_ae_single.transform(X_train_ae_single_flat).reshape(X_train_ae_single.shape)\n",
    "X_val_ae_single_norm = scaler_ae_single.transform(X_val_ae_single.reshape(-1, 1)).reshape(X_val_ae_single.shape)\n",
    "\n",
    "X_train_ae_single_reshaped = X_train_ae_single_norm[:, np.newaxis, :]\n",
    "X_val_ae_single_reshaped = X_val_ae_single_norm[:, np.newaxis, :]\n",
    "\n",
    "X_train_ae_tensor_s = torch.tensor(X_train_ae_single_reshaped, dtype=torch.float32)\n",
    "X_val_ae_tensor_s = torch.tensor(X_val_ae_single_reshaped, dtype=torch.float32)\n",
    "\n",
    "train_loader_ae_single = DataLoader(TensorDataset(X_train_ae_tensor_s, X_train_ae_tensor_s), batch_size=AE_BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader_ae_single = DataLoader(TensorDataset(X_val_ae_tensor_s, X_val_ae_tensor_s), batch_size=AE_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "autoencoder_global = DilatedAutoencoderA(\n",
    "    encoding_dim=ENCODING_DIM_AE, dropout_rate=AE_DROPOUT_RATE, sequence_length_param=SEQUENCE_LENGTH\n",
    ").to(device)\n",
    "optimizer_ae_global = optim.AdamW(autoencoder_global.parameters(), lr=AE_LEARNING_RATE, weight_decay=AE_WEIGHT_DECAY)\n",
    "criterion_ae_global = nn.MSELoss()\n",
    "scheduler_ae_global = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ae_global, mode='min', factor=0.2, patience=AE_PATIENCE_SINGLE//2, min_lr=1e-6, verbose=False)\n",
    "\n",
    "best_val_loss_ae_global = float('inf')\n",
    "patience_counter_ae_global = 0\n",
    "best_encoder_state_dict_global = None\n",
    "history_ae_train_loss_single = []\n",
    "history_ae_val_loss_single = []\n",
    "\n",
    "print(\"Starting single AE training...\")\n",
    "for epoch in range(AE_TRAIN_EPOCHS_SINGLE):\n",
    "    autoencoder_global.train()\n",
    "    train_loss_epoch_ae = 0.0\n",
    "    for batch_X, _ in train_loader_ae_single:\n",
    "        batch_X_original = batch_X.to(device)\n",
    "        batch_X_noisy = add_noise_to_batch(batch_X_original.clone(), AE_INPUT_NOISE_STD, device, autoencoder_global.training)\n",
    "        optimizer_ae_global.zero_grad()\n",
    "        outputs = autoencoder_global(batch_X_noisy)\n",
    "        loss = criterion_ae_global(outputs, batch_X_original)\n",
    "        loss.backward(); optimizer_ae_global.step()\n",
    "        train_loss_epoch_ae += loss.item() * batch_X_original.size(0)\n",
    "    train_loss_epoch_ae /= len(train_loader_ae_single.dataset)\n",
    "    history_ae_train_loss_single.append(train_loss_epoch_ae)\n",
    "\n",
    "    autoencoder_global.eval()\n",
    "    val_loss_epoch_ae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X_val, _ in val_loader_ae_single:\n",
    "            batch_X_val = batch_X_val.to(device)\n",
    "            outputs_val = autoencoder_global(batch_X_val)\n",
    "            loss_val = criterion_ae_global(outputs_val, batch_X_val)\n",
    "            val_loss_epoch_ae += loss_val.item() * batch_X_val.size(0)\n",
    "    val_loss_epoch_ae /= len(val_loader_ae_single.dataset)\n",
    "    history_ae_val_loss_single.append(val_loss_epoch_ae)\n",
    "    \n",
    "    current_lr_ae = optimizer_ae_global.param_groups[0]['lr']\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == AE_TRAIN_EPOCHS_SINGLE:\n",
    "        print(f\"  Single AE Epoch {epoch+1}/{AE_TRAIN_EPOCHS_SINGLE} - Train Loss: {train_loss_epoch_ae:.6f} - Val Loss: {val_loss_epoch_ae:.6f} - LR: {current_lr_ae:.1e}\")\n",
    "    \n",
    "    scheduler_ae_global.step(val_loss_epoch_ae)\n",
    "    if val_loss_epoch_ae < best_val_loss_ae_global:\n",
    "        best_val_loss_ae_global = val_loss_epoch_ae\n",
    "        best_encoder_state_dict_global = autoencoder_global.encoder.state_dict()\n",
    "        patience_counter_ae_global = 0\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == AE_TRAIN_EPOCHS_SINGLE: # 驻住  砖驻专\n",
    "             print(f\"    New best AE val_loss: {best_val_loss_ae_global:.6f}. Encoder state saved.\")\n",
    "    else:\n",
    "        patience_counter_ae_global += 1\n",
    "        if patience_counter_ae_global >= AE_PATIENCE_SINGLE:\n",
    "            print(f\"  Single AE Early stopping at epoch {epoch+1}. Best Val Loss: {best_val_loss_ae_global:.6f}\")\n",
    "            break\n",
    "\n",
    "if best_encoder_state_dict_global is None:\n",
    "    print(\"Error: AE training did not produce a best encoder state. This might happen if epochs are too few or data is problematic. Exiting.\")\n",
    "    exit()\n",
    "print(f\"Single AE training finished. Best Val Loss: {best_val_loss_ae_global:.6f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_ae_train_loss_single, label='Single AE Train Loss', color='dodgerblue')\n",
    "plt.plot(history_ae_val_loss_single, label='Single AE Validation Loss', color='orangered', linestyle='--')\n",
    "plt.title(f'Single Autoencoder Training Loss\\nBest Val Loss: {best_val_loss_ae_global:.6f}')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss (MSE)'); plt.legend(); plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "if AE_PLOT_RECONSTRUCTION_SINGLE:\n",
    "    print(\"\\nDisplaying reconstructions from the best single AE model...\")\n",
    "    autoencoder_global.encoder.load_state_dict(best_encoder_state_dict_global) # Ensure best encoder is used\n",
    "    plot_ae_reconstructions(autoencoder_global, val_loader_ae_single, device, num_samples=3, epoch_num=\"Final (Best Single AE)\", \n",
    "                            current_loss=best_val_loss_ae_global, sequence_length_param=SEQUENCE_LENGTH, plot_now=True, title_prefix=\"Single\")\n",
    "\n",
    "\n",
    "# --- K-Fold Cross-Validation (注专 Classifier , 注 拽专 ) ---\n",
    "# 砖转砖 - X_for_kfold_and_ae_val - y_for_kfold_and_ae_val 注专 -K-Fold 砖 -Classifier.\n",
    "# 拽爪转  住驻转  X_test_final, y_test_final.\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "fold_clf_train_losses, fold_clf_val_losses = [], []\n",
    "fold_clf_train_accs, fold_clf_val_accs = [], []\n",
    "fold_clf_test_accs = []\n",
    "fold_clf_test_reports = []\n",
    "all_y_true_test_final, all_y_pred_test_final = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_for_kfold_and_ae_val, y_for_kfold_and_ae_val)):\n",
    "    print(f\"\\n--- Classifier K-Fold: Fold {fold_idx + 1}/{N_SPLITS} ---\")\n",
    "    \n",
    "    X_train_fold_clf, X_val_fold_clf = X_for_kfold_and_ae_val[train_idx], X_for_kfold_and_ae_val[val_idx]\n",
    "    y_train_fold_clf, y_val_fold_clf = y_for_kfold_and_ae_val[train_idx], y_for_kfold_and_ae_val[val_idx]\n",
    "\n",
    "    # 专 住驻爪驻 -fold 砖 -Classifier (注 住住 转  砖 -fold)\n",
    "    scaler_clf_fold = StandardScaler()\n",
    "    X_train_flat_fold_clf = X_train_fold_clf.reshape(-1, 1); scaler_clf_fold.fit(X_train_flat_fold_clf)\n",
    "    X_train_normalized_fold_clf = scaler_clf_fold.transform(X_train_flat_fold_clf).reshape(X_train_fold_clf.shape)\n",
    "    X_val_normalized_fold_clf = scaler_clf_fold.transform(X_val_fold_clf.reshape(-1, 1)).reshape(X_val_fold_clf.shape)\n",
    "    \n",
    "    # 专 拽爪转  爪转 注 -scaler 砖 -fold  (砖!)\n",
    "    X_test_final_normalized_fold = scaler_clf_fold.transform(X_test_final.reshape(-1, 1)).reshape(X_test_final.shape)\n",
    "\n",
    "    X_train_reshaped_fold_clf = X_train_normalized_fold_clf[:, np.newaxis, :]\n",
    "    X_val_reshaped_fold_clf = X_val_normalized_fold_clf[:, np.newaxis, :]\n",
    "    X_test_final_reshaped_fold_clf = X_test_final_normalized_fold[:, np.newaxis, :]\n",
    "\n",
    "    X_train_tensor_f_clf = torch.tensor(X_train_reshaped_fold_clf, dtype=torch.float32)\n",
    "    y_train_tensor_f_clf = torch.tensor(y_train_fold_clf, dtype=torch.long)\n",
    "    X_val_tensor_f_clf = torch.tensor(X_val_reshaped_fold_clf, dtype=torch.float32)\n",
    "    y_val_tensor_f_clf = torch.tensor(y_val_fold_clf, dtype=torch.long)\n",
    "    X_test_final_tensor_f_clf = torch.tensor(X_test_final_reshaped_fold_clf, dtype=torch.float32)\n",
    "    y_test_final_tensor_f_clf = torch.tensor(y_test_final, dtype=torch.long)\n",
    "\n",
    "    train_loader_clf_f = DataLoader(TensorDataset(X_train_tensor_f_clf, y_train_tensor_f_clf), batch_size=CLASSIFIER_BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader_clf_f = DataLoader(TensorDataset(X_val_tensor_f_clf, y_val_tensor_f_clf), batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader_clf_final_f = DataLoader(TensorDataset(X_test_final_tensor_f_clf, y_test_final_tensor_f_clf), batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    encoder_for_clf_f = DilatedConvEncoderA(encoding_dim=ENCODING_DIM_AE, dropout_rate=AE_DROPOUT_RATE).to(device)\n",
    "    encoder_for_clf_f.load_state_dict(best_encoder_state_dict_global)\n",
    "    \n",
    "    classifier_f = SingleStrongClassifier(\n",
    "        encoder_for_clf_f, encoding_dim=ENCODING_DIM_AE, num_classes=num_unique_classes\n",
    "    ).to(device)\n",
    "    \n",
    "    manual_weights_list = [2.5, 2.0, 1.0] \n",
    "    class_weights_tensor_f = torch.tensor(manual_weights_list, dtype=torch.float32).to(device)\n",
    "    criterion_clf_f = nn.CrossEntropyLoss(weight=class_weights_tensor_f, label_smoothing=0.1)\n",
    "    # 驻爪 专拽 注 驻专专 砖 住  拽专 拽驻,  注   驻砖专 fine-tuning\n",
    "    params_to_optimize = classifier_f.parameters() # By default optimizes all (encoder fine-tuning + classifier)\n",
    "    # if FREEZE_ENCODER_IN_CLASSIFIER_KFOLD: # Add a flag if you want to test this\n",
    "    #     for param in classifier_f.encoder.parameters():\n",
    "    #         param.requires_grad = False\n",
    "    #     params_to_optimize = classifier_f.classifier.parameters()\n",
    "\n",
    "    optimizer_clf_f = optim.AdamW(params_to_optimize, lr=CLASSIFIER_LR, weight_decay=CLASSIFIER_WEIGHT_DECAY, betas=(0.9, 0.999))\n",
    "    scheduler_clf_f = get_cosine_scheduler(optimizer_clf_f, num_epochs=CLASSIFIER_EPOCHS, warmup_epochs=max(1, CLASSIFIER_EPOCHS // 10))\n",
    "\n",
    "    best_val_acc_clf_f = 0.0\n",
    "    patience_counter_clf_f = 0\n",
    "    current_fold_clf_train_losses, current_fold_clf_val_losses = [], []\n",
    "    current_fold_clf_train_accs, current_fold_clf_val_accs = [], []\n",
    "    best_classifier_state_dict_f = None\n",
    "\n",
    "    print(f\"  Starting Classifier training for Fold {fold_idx+1}...\")\n",
    "    for epoch in range(CLASSIFIER_EPOCHS):\n",
    "        classifier_f.train()\n",
    "        train_loss_clf, train_correct_clf, train_total_clf = 0.0, 0, 0\n",
    "        for batch_X, batch_y in train_loader_clf_f:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            aug_batch_X, aug_batch_y = [], []\n",
    "            for i in range(batch_X.shape[0]):\n",
    "                aug_batch_X.append(batch_X[i])\n",
    "                aug_batch_y.append(batch_y[i])\n",
    "                for _ in range(CLASSIFIER_NUM_AUG_PER_SAMPLE):\n",
    "                    # advanced_seismic_augmentation expects 1D tensor (signal only)\n",
    "                    aug_sample = advanced_seismic_augmentation(batch_X[i].squeeze(0)) # remove channel dim\n",
    "                    aug_batch_X.append(aug_sample.unsqueeze(0)) # add channel dim back\n",
    "                    aug_batch_y.append(batch_y[i])\n",
    "            \n",
    "            combined_X = torch.stack(aug_batch_X).to(device)\n",
    "            combined_y = torch.stack(aug_batch_y).to(device)\n",
    "            \n",
    "            optimizer_clf_f.zero_grad()\n",
    "            outputs = classifier_f(combined_X)\n",
    "            loss = criterion_clf_f(outputs, combined_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(params_to_optimize, max_norm=1.0) # Clip gradients for parameters being optimized\n",
    "            optimizer_clf_f.step()\n",
    "            \n",
    "            train_loss_clf += loss.item() * combined_X.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct_clf += (predicted == combined_y).sum().item()\n",
    "            train_total_clf += combined_y.size(0)\n",
    "        \n",
    "        train_loss_clf /= train_total_clf if train_total_clf > 0 else 1\n",
    "        train_acc_clf = train_correct_clf / train_total_clf if train_total_clf > 0 else 0\n",
    "        current_fold_clf_train_losses.append(train_loss_clf)\n",
    "        current_fold_clf_train_accs.append(train_acc_clf)\n",
    "\n",
    "        classifier_f.eval()\n",
    "        val_loss_clf, val_correct_clf, val_total_clf = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader_clf_f:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = classifier_f(batch_X)\n",
    "                loss = criterion_clf_f(outputs, batch_y)\n",
    "                val_loss_clf += loss.item() * batch_X.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct_clf += (predicted == batch_y).sum().item()\n",
    "                val_total_clf += batch_y.size(0)\n",
    "        \n",
    "        val_loss_clf /= val_total_clf if val_total_clf > 0 else 1\n",
    "        val_acc_clf = val_correct_clf / val_total_clf if val_total_clf > 0 else 0\n",
    "        current_fold_clf_val_losses.append(val_loss_clf)\n",
    "        current_fold_clf_val_accs.append(val_acc_clf)\n",
    "        scheduler_clf_f.step()\n",
    "        current_lr_clf = optimizer_clf_f.param_groups[0]['lr']\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == CLASSIFIER_EPOCHS:\n",
    "            print(f\"    CLF Fold {fold_idx+1} Epoch {epoch+1:3d}/{CLASSIFIER_EPOCHS} | Train: Loss={train_loss_clf:.4f}, Acc={train_acc_clf:.4f} | Val: Loss={val_loss_clf:.4f}, Acc={val_acc_clf:.4f} | LR={current_lr_clf:.1e}\")\n",
    "\n",
    "        if val_acc_clf > best_val_acc_clf_f:\n",
    "            best_val_acc_clf_f = val_acc_clf\n",
    "            best_classifier_state_dict_f = classifier_f.state_dict()\n",
    "            patience_counter_clf_f = 0\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == CLASSIFIER_EPOCHS:\n",
    "                print(f\"      New best CLF val_acc for Fold {fold_idx+1}: {best_val_acc_clf_f:.4f}. Model state saved.\")\n",
    "        else:\n",
    "            patience_counter_clf_f += 1\n",
    "            if patience_counter_clf_f >= CLASSIFIER_PATIENCE:\n",
    "                print(f\"    CLF Early stopping at epoch {epoch+1} for Fold {fold_idx+1}. Best val_acc: {best_val_acc_clf_f:.4f}\")\n",
    "                break\n",
    "    \n",
    "    fold_clf_train_losses.append(current_fold_clf_train_losses)\n",
    "    fold_clf_val_losses.append(current_fold_clf_val_losses)\n",
    "    fold_clf_train_accs.append(current_fold_clf_train_accs)\n",
    "    fold_clf_val_accs.append(current_fold_clf_val_accs)\n",
    "    print(f\"  Best CLF Validation Accuracy for Fold {fold_idx+1}: {best_val_acc_clf_f:.4f}\")\n",
    "\n",
    "    if best_classifier_state_dict_f:\n",
    "        classifier_f.load_state_dict(best_classifier_state_dict_f)\n",
    "    else:\n",
    "        print(f\"  Warning: No best classifier state dict saved for fold {fold_idx+1}. Using last state for test evaluation.\")\n",
    "\n",
    "    classifier_f.eval()\n",
    "    y_true_test_f, y_pred_test_f = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader_clf_final_f:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = classifier_f(batch_X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_test_f.extend(batch_y.cpu().numpy())\n",
    "            y_pred_test_f.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    all_y_true_test_final.extend(y_true_test_f)\n",
    "    all_y_pred_test_final.extend(y_pred_test_f)\n",
    "    \n",
    "    test_acc_f = accuracy_score(y_true_test_f, y_pred_test_f)\n",
    "    fold_clf_test_accs.append(test_acc_f)\n",
    "    report_f = classification_report(y_true_test_f, y_pred_test_f, target_names=['quiet', 'vehicle', 'human'], output_dict=True, zero_division=0)\n",
    "    fold_clf_test_reports.append(report_f)\n",
    "    print(f\"  Fold {fold_idx+1} Test Accuracy on final test set: {test_acc_f:.4f}\")\n",
    "\n",
    "\n",
    "# --- 住 转爪转 K-Fold (注专 -Classifier) ---\n",
    "print(\"\\n\\n--- Classifier K-Fold Cross-Validation Summary (using pre-trained AE) ---\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "avg_clf_train_loss, std_clf_train_loss = aggregate_curves(fold_clf_train_losses)\n",
    "avg_clf_val_loss, std_clf_val_loss = aggregate_curves(fold_clf_val_losses)\n",
    "avg_clf_train_acc, std_clf_train_acc = aggregate_curves(fold_clf_train_accs)\n",
    "avg_clf_val_acc, std_clf_val_acc = aggregate_curves(fold_clf_val_accs)\n",
    "\n",
    "if avg_clf_train_loss.size > 0: # Check if aggregation was successful\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(avg_clf_train_loss, label='Avg CLF Train Loss', color='forestgreen')\n",
    "    plt.fill_between(range(len(avg_clf_train_loss)), avg_clf_train_loss - std_clf_train_loss, avg_clf_train_loss + std_clf_train_loss, color='forestgreen', alpha=0.2)\n",
    "    plt.title(f'Avg Classifier Training Loss ({N_SPLITS} Folds)')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('CrossEntropy Loss'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(avg_clf_val_loss, label='Avg CLF Validation Loss', color='gold')\n",
    "    plt.fill_between(range(len(avg_clf_val_loss)), avg_clf_val_loss - std_clf_val_loss, avg_clf_val_loss + std_clf_val_loss, color='gold', alpha=0.2)\n",
    "    plt.title(f'Avg Classifier Validation Loss ({N_SPLITS} Folds)')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('CrossEntropy Loss'); plt.legend(); plt.grid(True)\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"Could not generate classifier loss plots (no data).\")\n",
    "\n",
    "\n",
    "if avg_clf_train_acc.size > 0:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(avg_clf_train_acc, label='Avg CLF Train Accuracy', color='mediumpurple')\n",
    "    plt.fill_between(range(len(avg_clf_train_acc)), avg_clf_train_acc - std_clf_train_acc, avg_clf_train_acc + std_clf_train_acc, color='mediumpurple', alpha=0.2)\n",
    "    plt.title(f'Avg Classifier Training Accuracy ({N_SPLITS} Folds)')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.ylim(0, 1.05); plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(avg_clf_val_acc, label='Avg CLF Validation Accuracy', color='darkorange')\n",
    "    plt.fill_between(range(len(avg_clf_val_acc)), avg_clf_val_acc - std_clf_val_acc, avg_clf_val_acc + std_clf_val_acc, color='darkorange', alpha=0.2)\n",
    "    plt.title(f'Avg Classifier Validation Accuracy ({N_SPLITS} Folds)')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.ylim(0, 1.05); plt.grid(True)\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"Could not generate classifier accuracy plots (no data).\")\n",
    "\n",
    "\n",
    "if fold_clf_test_accs:\n",
    "    mean_test_acc = np.mean(fold_clf_test_accs)\n",
    "    std_test_acc = np.std(fold_clf_test_accs)\n",
    "    print(f\"\\nAverage Test Accuracy over {N_SPLITS} Folds: {mean_test_acc:.4f} +/- {std_test_acc:.4f}\")\n",
    "    print(f\"Individual Fold Test Accuracies: {[f'{acc:.4f}' for acc in fold_clf_test_accs]}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.boxplot(data=fold_clf_test_accs, palette='viridis', width=0.3)\n",
    "    plt.title(f'Test Accuracies Across {N_SPLITS} Folds\\nMean: {mean_test_acc:.4f} (Std: {std_test_acc:.4f})')\n",
    "    plt.ylabel('Test Accuracy'); plt.xticks([0], [f'{N_SPLITS}-Fold CV']); plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No test accuracies recorded for folds.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Final Evaluation on Aggregated Test Set Predictions (Classifier K-Fold) ---\")\n",
    "target_names = ['quiet', 'vehicle', 'human'] # Make sure these match your label_encoding\n",
    "if all_y_true_test_final and all_y_pred_test_final:\n",
    "    final_accuracy_agg = accuracy_score(all_y_true_test_final, all_y_pred_test_final)\n",
    "    print(f\"Overall Accuracy on Final Test Set (Aggregated from {N_SPLITS} folds): {final_accuracy_agg:.4f}\")\n",
    "    print(\"\\nOverall Classification Report (Aggregated):\")\n",
    "    print(classification_report(all_y_true_test_final, all_y_pred_test_final, target_names=target_names, zero_division=0))\n",
    "\n",
    "    cm_final_agg = confusion_matrix(all_y_true_test_final, all_y_pred_test_final)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_final_agg, annot=True, fmt='d', cmap='Blues_r', \n",
    "                xticklabels=target_names, yticklabels=target_names, annot_kws={\"size\": 14})\n",
    "    plt.title(f'Aggregated Confusion Matrix - Final Test Set\\nOverall Accuracy: {final_accuracy_agg:.4f}', fontsize=15)\n",
    "    plt.ylabel('True Label', fontsize=12); plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.xticks(fontsize=10); plt.yticks(fontsize=10); plt.show()\n",
    "else:\n",
    "    print(\"No aggregated test predictions available to generate final report and confusion matrix.\")\n",
    "\n",
    "\n",
    "print(f\"\\n Summary of Classifier K-Fold Cross-Validation (using pre-trained AE):\")\n",
    "if fold_clf_test_accs:\n",
    "    print(f\"  Number of Folds (N_SPLITS): {N_SPLITS}\")\n",
    "    print(f\"  Average Test Accuracy: {mean_test_acc:.4f} (Std: {std_test_acc:.4f})\")\n",
    "if all_y_true_test_final:\n",
    "    print(f\"  Overall Accuracy (on aggregated predictions from all folds' test runs): {final_accuracy_agg:.4f if 'final_accuracy_agg' in locals() else 'N/A'}\")\n",
    "print(\"--- End of Script ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
